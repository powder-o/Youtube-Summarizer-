{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c78714b1-9c11-4fb0-82de-b101c0964cd6",
   "metadata": {},
   "source": [
    "*My friends asked me to post something that would help them to learn stuff like this without actually spending hours on tutorials from various source.*\n",
    "*So I made this as descriptive as possible so even a **beginner** might understand. This notebook combines my learnings from various sources.* \n",
    "\n",
    "***I hope this helps.***\n",
    "\n",
    "\n",
    "# YouTube Video Summarizer\n",
    "\n",
    "This notebook aims to summarize YouTube video transcripts using different techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e471cd-4b4c-4207-8ed8-c2fa586ba6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress all warnings\n",
    "\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb86c4c-7dd3-43bd-b531-2ba1d76bfe3d",
   "metadata": {},
   "source": [
    "## The TF-IDF (Term Frequency-Inverse Document Frequency) approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4a919-7abd-4f28-9dd2-06e0d3c03e36",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "1. **Transcript Extraction**: The summarizer begins by extracting the transcript from a YouTube video using the `YouTubeTranscriptApi` library. The transcript is converted into a single text string.\r\n",
    "\r\n",
    "2. **Sentence Tokenization**: The text is then split into individual sentences using NLTK's `sent_tokenize` function, which helps maintain the integrity of each sentence for further processing.\r\n",
    "\r\n",
    "3. **TF-IDF Calculation**: The TF-IDF vectorizer from the `scikit-learn` library is used to calculate the importance of each sentence. TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. It is calculated by multiplying two metrics:\r\n",
    "   - **Term Frequency (TF)**: This measures how frequently a term appears in a document. The more frequently a term appears, the higher its TF value.\r\n",
    "   - **Inverse Document Frequency (IDF)**: This measures how unique or rare a term is across all documents in the corpus. If a term appears in many documents, its IDF value is low, indicating that the term is not unique or informative.\r\n",
    "   \r\n",
    "   TF-IDF is computed by multiplying TF and IDF for each term. The resulting value reflects the importance of the term: it is high for terms that occur frequently in the current document but rarely in the entire corpus. In the context of summarization, TF-IDF helps in determining the sentences that contain the most informative words, allowing us to assign importance scores to each sentence.\r\n",
    "\r\n",
    "4. **Sentence Scoring and Selection**: After calculating the TF-IDF values for each term, the sum of the TF-IDF scores for each sentence is used to determine its importance. The sentences with the highest scores are selected for the summary.\r\n",
    "\r\n",
    "5. **Sentence Ordering**: To maintain coherence, the selected sentences are reordered based on their original positions in the transcript.\r\n",
    "\r\n",
    "6. **Summary Generation**: Finally, the ordered sentences are joined together to generate a concise summary of the transcript.\r\n",
    "\r\n",
    "The TF-IDF approach ensures that the most relevant sentences are selected for summarization based on the importance of the words they contain, making the generated summary informative and efficient.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cfe2017-cc1e-4e25-9afa-4865fde17fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtube_transcript_api\n",
    "from youtube_transcript_api import YouTubeTranscriptApi #for downloading transcripts\n",
    "import nltk # Natural Language Toolkit\n",
    "import re # helps with text processing tasks such as pattern matching, search, and substitution.\n",
    "from nltk.corpus import stopwords #This imports a list of common words (like \"and\", \"the\", etc.) from the Natural Language Toolkit (NLTK) that are often removed from text data during preprocessing to improve efficiency in NLP tasks.\n",
    "import sklearn # Most basic ML library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # used to convert text into numerical features by calculating the Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "import numpy as np # used for numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7102c30-6510-4b4c-8a24-4b3f4e2b611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')  # Tokenizer model for splitting text into sentences\n",
    "nltk.download('punkt_tab')  # Additional data required for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe05bfe-3c93-427c-a2ca-df29f2de1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube video link and extraction of unique ID\n",
    "link = \"https://www.youtube.com/watch?v=Y8Tko2YC5hA\"\n",
    "unique_id = link.split(\"=\")[-1]  # Extract the video ID from the link\n",
    "# 'Y8Tko2YC5hA' this is the so called unique id of a yt video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65fb8c9-f41b-4bb5-91bc-1648ba574ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching transcript\n",
    "try:\n",
    "    sub = YouTubeTranscriptApi.get_transcript(unique_id)  # Fetch the transcript \n",
    "except youtube_transcript_api.exceptions.TranscriptsDisabled:\n",
    "    print(\"Transcripts are disabled for this video.\")\n",
    "    exit()  # Exit the program if transcripts are not available\n",
    "except youtube_transcript_api.exceptions.NoTranscriptFound:\n",
    "    print(\"No transcript found for this video.\")\n",
    "    exit()  # Exit the program if no transcript is found\n",
    "\n",
    "# the except is used for error handling these errors can also be used for logging.\n",
    "# whats logging? - when running big complex programs, its used to record events or errors which helps in debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b593c005-7b59-4b13-8137-5af5f4f16dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining transcript parts into a single string\n",
    "subtitle = \" \".join([x['text'] for x in sub])  # Join each piece of text from the transcript into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d95d300-d505-407b-9081-05d1184b7441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this video, I\\'m going to answer the top 3 questions my students ask me about Python. What is Python? What  can you do with it? And why is it so popular? In other words, what does it do that other programming languages don\\'t? Python is the  world\\'s fastest growing and most popular programming language, not just  amongst software engineers, but also amongst mathematicians,  data analysts, scientists, accountants, networking engineers, and even kids! Because it\\'s a very beginner friendly programming  language. So people from different disciplines use Python for a variety of different tasks, such as data analysis and visualization,  artificial intelligence and machine learning, automation  in fact this is one of the big uses of Python amongst people who are not software developers. If you constantly have to do boring, repetitive  tasks, such as copying files and folders around, renaming them,  uploading them to a server, you can easily write a Python script to automate all that and save your time. And that\\'s just one example, if you continuously have to work with excel spreadsheets, PDF\\'s, CS View files, download websites and parse them, you can automate all that stuff with Python. So you don\\'t have to be a software developer to use Python. You could be an accountant, a mathematician, or a scientist, and use Python  to make your life easier. You can also use Python to build  web, mobile and desktop applications as well as software  testing or even hacking. So Python is a multi purpose language.  Now if you have some programming experience you may say, \"But Mosh we can do all this stuff with other programming languages, so what\\'s the big deal  about Python?\" Here are a few reasons. With Python you can  solve complex problems in less time with fewer lines of code.  Here\\'s an example. Let\\'s say we want to extract the first three  letters of the text Hello World. This is the code we have to write  in C# this is how we do it in JavaScript and here\\'s how we  do it in Python. See how short and clean the language is? And that\\'s just the beginning. Python makes a lot of trivial things really easy with a simple yet powerful syntax. Here are a few other reasons Python is so popular. It\\'s a high level language so you don\\'t have to worry about complex tasks such as memory management,  like you do in C++. It\\'s cross platform which means  you can build and run Python applications on Windows, Mac,  and Linux. It has a huge community so whenever you get  stuck, there is someone out there to help. It has a large ecosystem  of libraries, frameworks and tools which means whatever you wanna do it is likely that someone else has done it before because Python has been around  for over 20 years. So in a nutshell, Python is a multi-purpose language with a simple, clean, and beginner-friendly  syntax. All of that means Python is awesome. Technically everything you do with Python you can do with other programming languages,  but Python\\'s simplicity and elegance has made it grow way  more than other programming languages. That\\'s why it\\'s the number onne language employers are looking for. So whether you\\'re a programmer or  an absolute beginner, learning Python opens up lots of job opportunities  to you. In fact, the average Python developer earns a whopping 116,000 dollars a year. If you found this video helpful, please support my hard work by liking and sharing it with others.  Also, be sure to subscribe to my channel, because I have a couple of awesome Python tutorials for you, you\\'re going to see them on the screen now.  Here\\'s my Python tutorial for beginners, it\\'s a great starting point if you  have limited or no programming experience. On the other hand, if you  do have some programming experience and want to quickly get up to speed with Python,  I have another tutorial just for you. I\\'m not going to waste your time  telling you what a variable or a function is. I will talk to you like a programmer. There\\'s never been a better time to master Python programming, so click on the tutorial that is right for you and get started. Thank you for watching!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40189fa0-0eb9-49b7-acf5-48080d9e4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import sent_tokenize\n",
    "subtitle = subtitle.replace(\"\\n\", \" \")  # Replace newline characters with spaces\n",
    "sentences = sent_tokenize(subtitle)  # Split the transcript into individual sentences\n",
    "organized_sent = {k: v for v, k in enumerate(sentences)}  # Create a dictionary mapping each sentence to its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00285125-cfe4-4978-aa66-afe1aa92417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Calculation\n",
    "tf_idf = TfidfVectorizer(min_df=2,  # Ignore terms that appear in fewer than 2 documents\n",
    "                         strip_accents='unicode',  # Remove accents and normalize characters\n",
    "                         max_features=None,  # Use all features available (no limit on features)\n",
    "                         lowercase=True,  # Convert all characters to lowercase\n",
    "                         token_pattern=r'\\w{1,}',  # Token pattern to use for tokenizing the text\n",
    "                         ngram_range=(1, 3),  # Use unigrams, bigrams, and trigrams\n",
    "                         use_idf=True,  # Use inverse document frequency for calculating TF-IDF\n",
    "                         smooth_idf=True,  # Smooth the idf weights by adding 1 to document frequencies\n",
    "                         sublinear_tf=True,  # Apply sublinear tf scaling (use 1 + log(tf))\n",
    "                         stop_words='english')  # Remove common English stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7f0bd14-1ef6-4ea1-91ef-c26af6e4ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform sentences into TF-IDF vectors\n",
    "sentence_vectors = tf_idf.fit_transform(sentences)\n",
    "# Sum TF-IDF scores for each sentence\n",
    "sent_scores = np.array(sentence_vectors.sum(axis=1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d913890-071e-4589-b25d-60cf451631f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Top N Sentences\n",
    "N = 3  # Number of sentences to select for the summary\n",
    "top_n_sentences = [sentences[index] for index in np.argsort(sent_scores, axis=0)[::-1][:N]]  # Select top N sentences with highest scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f67788b5-9c96-4805-b54d-1b9d3b2a159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the scored sentences with their indexes as in the subtitle\n",
    "mapped_sentences = [(sentence, organized_sent[sentence]) for sentence in top_n_sentences]  # Map each sentence to its original index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be1bab62-cb33-4c47-8df4-e434671af43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering the top-n sentences in their original order\n",
    "mapped_sentences = sorted(mapped_sentences, key=lambda x: x[1])  # Sort the selected sentences by their original index\n",
    "ordered_sentences = [element[0] for element in mapped_sentences]  # Extract the sentences in the correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f4e349f-0fa1-4e0e-88f0-ea264dc39797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Summary:\n",
      "Python is the  world's fastest growing and most popular programming language, not just  amongst software engineers, but also amongst mathematicians,  data analysts, scientists, accountants, networking engineers, and even kids! Now if you have some programming experience you may say, \"But Mosh we can do all this stuff with other programming languages, so what's the big deal  about Python?\" So in a nutshell, Python is a multi-purpose language with a simple, clean, and beginner-friendly  syntax.\n"
     ]
    }
   ],
   "source": [
    "# Joining the ordered sentences to form the summary\n",
    "summary = \" \".join(ordered_sentences)  # Join the ordered sentences to form the summary\n",
    "print(\"TF-IDF Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea0200-ed18-41c9-a891-85f1e5f54d6e",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7005318-bdcf-405e-ad18-ec708759ec1a",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a0bd8-6473-4cc2-838e-67768d050d05",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90f251-7477-4f95-b3fa-b7f905ba00d8",
   "metadata": {},
   "source": [
    "## BART Technique Overview\r\n",
    "This section useses the BART transformer model from the `transformers` library by Hugging Face to summarize YouTube video transcripts. BART is an encoder-decoder model designed for natural language generation tasks, including summarization.\r\n",
    "\r\n",
    "#### BART Summarization Steps\r\n",
    "\r\n",
    "1. **Transcript Extraction**: Extract the transcript using the `YouTubeTranscriptApi` and join it into a single text string.\r\n",
    "\r\n",
    "2. **BART Model Setup**: Load the pre-trained BART model (`facebook/bart-large-cnn`) and its tokenizer to prepare the input text.\r\n",
    "\r\n",
    "3. **Dynamic Input Length**: Adjust the input length dynamically to retain important information and tokenize the input.\r\n",
    "\r\n",
    "4. **Summary Generation**: Generate a summary using the BART model with parameters like `max_length`, `min_length`, `length_penalty`, and `num_beams` to control output quality.\r\n",
    "\r\n",
    "5. **Pipeline Summarization**: Use the `pipeline` function for easy summarization with automatic parameter handling.\r\n",
    "\r\n",
    "#### Advantages of BART\r\n",
    "- **Contextual Understanding**: Uses transformer-based attention for context-aware summaries.\r\n",
    "- **Flexibility**: Adjustable parameters for different types of content.\r\n",
    "- **Efficiency**: Pre-trained for summarization, providing accurate results.\r\n",
    "\r\n",
    "#### Summary Methods\r\n",
    "- **Direct BART**: Allows fine control over summarization parameters.\r\n",
    "- **Pipeline**: Simplifies the process with automated handling of steps.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffc9928e-9103-47b8-9c21-f4b505ca8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers # most basic gen ai library. get familiar with it\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration # importing the BART model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ff6fc-2241-4f43-9000-eb75fc709152",
   "metadata": {},
   "source": [
    "The downloading the transcript step are the same, I just repeated them so that you can revise them. Thats why there are no comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21907e8f-ca1c-47b8-8635-ca995912ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a691f1-3afd-440c-82f9-8a19c09f52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.youtube.com/watch?v=Y8Tko2YC5hA\"\n",
    "unique_id = link.split(\"=\")[-1]  \n",
    "\n",
    "try:\n",
    "    sub = YouTubeTranscriptApi.get_transcript(unique_id)  \n",
    "    if not sub:\n",
    "        raise ValueError(\"Transcript is empty.\")  \n",
    "except youtube_transcript_api.exceptions.TranscriptsDisabled:\n",
    "    print(\"Transcripts are disabled for this video.\")\n",
    "    exit()  \n",
    "except youtube_transcript_api.exceptions.NoTranscriptFound:\n",
    "    print(\"No transcript found for this video.\")\n",
    "    exit() \n",
    "\n",
    "\n",
    "subtitle = \" \".join([x['text'] for x in sub]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf15fe94-1836-494e-ac33-993af727f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BART model and tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')  # Load BART tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')  # Load BART model for summarization\n",
    "\n",
    "# you can also search for other models in hugging face. It contains thousands of such models, and thousands more for other tasks as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63200906-c3cc-4148-99b4-dc41226ae73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input subtitle with a limit on the maximum length\n",
    "input_length = len(subtitle.split())\n",
    "adjusted_max_length = min(1024, int(0.8 * input_length))  # Set max_length to be 80% of the input length, capped at 1024\n",
    "input_tensor = tokenizer.encode(subtitle, return_tensors=\"pt\", max_length=adjusted_max_length, truncation=True)  # Tokenize the input text with truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b573550-11f0-4e2b-ba5a-68eba0b78b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary using BART model with specified parameters\n",
    "outputs_tensor = model.generate(input_tensor, max_length=160, min_length=120, length_penalty=1.5, num_beams=6, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2420d56-3fc2-46be-bcfa-685cb8889ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART Summary:\n",
      "Python is the world's fastest growing and most popular programming language. It is used by mathematicians, data analysts, scientists, accountants, networking engineers, and even kids. With Python you can solve complex problems in less time with fewer lines of code. It's a high level language so you don't have to worry about complex tasks such as memory management, like you do in C++. It has a huge community so whenever you get  stuck, there is someone out there to help. You can also use Python to build  web, mobile and desktop applications as well as software  testing or even hacking.\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tensor to get the summary\n",
    "bart_summary = tokenizer.decode(outputs_tensor[0], skip_special_tokens=True)  # Decode the generated output to text\n",
    "print(\"BART Summary:\")\n",
    "print(bart_summary)  # Print the BART based summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9edd6d-4d29-49c3-85eb-a2d2e845acf0",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ce57c-87c9-410a-9431-6ebed5c7e264",
   "metadata": {},
   "source": [
    "### Alternative method using pipeline\n",
    "This is much easier than doing everything by yourself because it abstracts the nitty gritty stuff.\n",
    "\n",
    "Also keep one thing in mind, Professional coders never write the whole code. EVER. They always reuse their own code, or someone elses'. And coders try to abstract things as much as possible, by either using tools/libraries, the more nitty gritty stuff you handle harder is it to debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fac84bdf-c9f5-463c-9618-4713733d717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5fa9da2-cb1a-4b34-ab9d-54574e537fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create summarization pipeline\n",
    "summarizer = pipeline('summarization', model='facebook/bart-large-cnn')  # Create a summarization pipeline using BART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "141837fb-4340-40db-b044-dee4ba6d82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust max_length and min_length based on input length\n",
    "adjusted_max_length = min(180, int(0.4 * input_length))  # Set max_length to be 40% of the input length, capped at 180\n",
    "adjusted_min_length = min(30, int(0.1 * input_length))  # Set min_length to be 10% of the input length, capped at 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fed19643-055f-43f1-b499-64d17372a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BART Summary:\n",
      "Python is the world's fastest growing and most popular programming language. People from different disciplines use Python for a variety of different tasks. With Python you can solve complex problems in less time with fewer lines of code.\n"
     ]
    }
   ],
   "source": [
    "# Generate summary using the pipeline with adjusted parameters\n",
    "pipeline_summary = summarizer(subtitle, max_length=adjusted_max_length, min_length=adjusted_min_length, truncation=True)  # Generate summary with pipeline\n",
    "print(\"Pipeline BART Summary:\")\n",
    "print(pipeline_summary[0]['summary_text'])  # Print the summary generated by the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9815e-ed1a-4429-bc5b-cfd7146da927",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f8956-d699-47d2-b3fe-2353d7f5eccb",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613b81e-da13-45d6-901b-6bb009f5b1fe",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024f205-4fe2-4bf9-97b8-dfcdd1cd4d8a",
   "metadata": {},
   "source": [
    "# Langchain Youtube video summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8d303-84b2-4cf6-a95a-0941770b26f6",
   "metadata": {},
   "source": [
    "**Now lets use langchain to make this much more easier and abstract**\n",
    "\n",
    "Langchain abstracts a lot of stuff, and it is one of the most beginner friendly framework in GenAI (to my knowledge)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9f5f7-d889-45b1-bb36-7e7019333b52",
   "metadata": {},
   "source": [
    "\r\n",
    "Thi section t uses LangChain to summarize YouTube transcripts with two methods: **Stuff** and **Map Reduce**. LangChain provides an efficient and flexible way to create high-quality summaries by leveraging advanced language model capabilities.uctured.\r\n",
    "\r\n",
    "#### Why LangChain?\r\n",
    "\r\n",
    "Compared to traditional methods like TF-IDF and BART, LangChain offers several advantages that make it a superior choice for summarizing YouTube transcripts:\r\n",
    "\r\n",
    "1. **Scalability**: LangChain handles larger texts effectively by breaking them into smaller chunks and processing them efficiently. This makes it well-suited for lengthy transcripts that would be challenging for models with fixed input limits.\r\n",
    "\r\n",
    "2. **Modularity**: LangChain provides a modular framework that makes it easy to chain different LLM operations, such as splitting documents, summarizing sections, and combining summaries. This modularity allows for greater flexibility and customization in the summarization process, enabling users to adapt the approach based on the specific needs of the content.\r\n",
    "\r\n",
    "3. **LLM Integration**: LangChain seamlessly integrates with advanced LLMs, offering better customization, parameter control, and the ability to dynamically adjust prompts to suit different scenarios. This results in more accurate and context-aware summaries, which are often difficult to achieve with traditional techniques alone.\r\n",
    "\r\n",
    "Using LangChain helps manage long transcripts effectively and produces high-quality summaries by employing adaptable strategies like Stuff and Map Reduce. These methods allow for a more nuanced approach to summarization, ensuring that key information is retained and that the final summary is both informative and concise. Traditional techniques like TF-IDF and fixed-length models like BART struggle with scalability and flexibility, which LangChain overcomes with ease.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05f0d90b-b367-410e-b81d-eabb1581de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8f59118-f3c2-4c4f-beb3-2a7b53efb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6827b67-a374-496b-9ae6-c2397faa89c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Y8Tko2YC5hA'}, page_content='In this video, I\\'m going to answer the top 3 questions my students ask me about Python. What is Python? What can you do with it? And why is it so popular? In other words, what does it do that other programming languages don\\'t? Python is the world\\'s fastest growing and most popular programming language, not just amongst software engineers, but also amongst mathematicians, data analysts, scientists, accountants, networking engineers, and even kids! Because it\\'s a very beginner friendly programming language. So people from different disciplines use Python for a variety of different tasks, such as data analysis and visualization, artificial intelligence and machine learning, automation in fact this is one of the big uses of Python amongst people who are not software developers. If you constantly have to do boring, repetitive tasks, such as copying files and folders around, renaming them, uploading them to a server, you can easily write a Python script to automate all that and save your time. And that\\'s just one example, if you continuously have to work with excel spreadsheets, PDF\\'s, CS View files, download websites and parse them, you can automate all that stuff with Python. So you don\\'t have to be a software developer to use Python. You could be an accountant, a mathematician, or a scientist, and use Python to make your life easier. You can also use Python to build web, mobile and desktop applications as well as software testing or even hacking. So Python is a multi purpose language. Now if you have some programming experience you may say, \"But Mosh we can do all this stuff with other programming languages, so what\\'s the big deal about Python?\" Here are a few reasons. With Python you can solve complex problems in less time with fewer lines of code. Here\\'s an example. Let\\'s say we want to extract the first three letters of the text Hello World. This is the code we have to write in C# this is how we do it in JavaScript and here\\'s how we do it in Python. See how short and clean the language is? And that\\'s just the beginning. Python makes a lot of trivial things really easy with a simple yet powerful syntax. Here are a few other reasons Python is so popular. It\\'s a high level language so you don\\'t have to worry about complex tasks such as memory management, like you do in C++. It\\'s cross platform which means you can build and run Python applications on Windows, Mac, and Linux. It has a huge community so whenever you get stuck, there is someone out there to help. It has a large ecosystem of libraries, frameworks and tools which means whatever you wanna do it is likely that someone else has done it before because Python has been around for over 20 years. So in a nutshell, Python is a multi-purpose language with a simple, clean, and beginner-friendly syntax. All of that means Python is awesome. Technically everything you do with Python you can do with other programming languages, but Python\\'s simplicity and elegance has made it grow way more than other programming languages. That\\'s why it\\'s the number onne language employers are looking for. So whether you\\'re a programmer or an absolute beginner, learning Python opens up lots of job opportunities to you. In fact, the average Python developer earns a whopping 116,000 dollars a year. If you found this video helpful, please support my hard work by liking and sharing it with others. Also, be sure to subscribe to my channel, because I have a couple of awesome Python tutorials for you, you\\'re going to see them on the screen now. Here\\'s my Python tutorial for beginners, it\\'s a great starting point if you have limited or no programming experience. On the other hand, if you do have some programming experience and want to quickly get up to speed with Python, I have another tutorial just for you. I\\'m not going to waste your time telling you what a variable or a function is. I will talk to you like a programmer. There\\'s never been a better time to master Python programming, so click on the tutorial that is right for you and get started. Thank you for watching!')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YouTube transcript using YoutubeLoader\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=Y8Tko2YC5hA\", add_video_info=False\n",
    ")  # Initialize the loader to fetch subtitles from the YouTube URL\n",
    "subtitles = loader.load()  # Load the subtitles as document objects\n",
    "subtitles\n",
    "# See this way of exporting the transcripts are much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d337f63-bbe1-43c2-854d-c7834088e7c5",
   "metadata": {},
   "source": [
    "Go to Groq website, signin and create an API key. Its free! (for personal use but yea)\n",
    "\n",
    "Save this API key in a safe place so that ou dont loose it, and dont share your api keys with anyone.\n",
    "\n",
    "then in the current directory create a file, rename it as '.env' or in jupyter as 'groq_api_token.env'\n",
    "\n",
    "Open it and write GROQ_API_TOKEN = \"--your key--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78295353-e08e-48ba-b715-89b31b3da9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv # for loading the .env file\n",
    "\n",
    "# Load environment variables and set up ChatGroq\n",
    "load_dotenv('groq_api_token.env')  # Load the environment variables from the specified .env file\n",
    "groq_key = os.getenv('GROQ_API_TOKEN')  # Retrieve the API token for Groq from environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc2e3eb4-8334-4f88-b904-d4cade923580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM using ChatGroq with specified parameters\n",
    "llm = ChatGroq(temperature=0, groq_api_key=groq_key, model_name=\"llama3-70b-8192\")  # Set temperature to 0 for deterministic output\n",
    "# the llama3 is an LLM and rather than exporting it through huggingface, groq and langchain makes it much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe709709-0a42-4eb5-ab4a-cc1e6bd19fcb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6ef1b3-d5d9-45b9-82e9-45dc971663aa",
   "metadata": {},
   "source": [
    "#### Stuff Method\n",
    "\n",
    "The **Stuff** method combines all the content into a single context and passes it to the LLM for summarization. This approach is straightforward and works well for shorter documents or when the entire input can fit within the model's length limit without truncation. By using the Stuff method, the LLM is able to consider all the information at once, leading to a cohesive summary that captures the essence of the entire content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f33c365f-5d66-4b22-8058-c1c0a313461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain #Combines multiple documents\n",
    "from langchain.chains.llm import LLMChain # Chain to call an llm\n",
    "from langchain_core.prompts import ChatPromptTemplate # Defines the structure of prompts that youll be passing to llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1b6e4ca-ecc9-4f27-8ad2-d59ecd2d82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for summarization\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Write a concise summary of the following:\\n\\n{context}\")]\n",
    ")  # Define a prompt that will instruct the LLM to summarize the given context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91af1605-0f2e-4d2d-9920-a52c6a678b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stuff Method Summary:\n",
      "Here is a concise summary of the video:\n",
      "\n",
      "The video answers the top 3 questions about Python: what it is, what it can do, and why it's so popular. Python is a beginner-friendly, multi-purpose language used by people from various disciplines for tasks like data analysis, automation, and web development. It's popular due to its simplicity, ease of use, and high-level syntax, making it ideal for solving complex problems quickly. Python's advantages include its cross-platform compatibility, large community, and extensive libraries. As a result, it's the most in-demand language by employers, with Python developers earning an average of $116,000 per year.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and invoke chain using the Stuff method\n",
    "chain = create_stuff_documents_chain(llm, prompt)  # Create a chain that uses all the content to generate a summary\n",
    "result = chain.invoke({\"context\": subtitles})  # Pass the subtitles as context to the chain and get the summary\n",
    "print(\"Stuff Method Summary:\")\n",
    "print(result)  # Print the result of the Stuff summarization method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ad63f-a912-4eea-adbc-4f8caed6f2ae",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52039a1e-b869-4944-b4e8-20644410bdc8",
   "metadata": {},
   "source": [
    "#### Map Reduce Method\n",
    "\n",
    "The **Map Reduce** method is designed to handle longer content that cannot be processed in a single pass. It splits the content into smaller, manageable chunks and summarizes each chunk independently in the **map** phase. In the **reduce** phase, these individual summaries are consolidated into a final, cohesive summary that captures the main themes and key points. This method is particularly useful for lengthy transcripts, ensuring that important information is not lost and that the final summary is comprehensive and well-structured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef4f01-80f5-4779-a7b3-3adf82e15915",
   "metadata": {},
   "source": [
    "The map reduce method is much used when you have a large document or here- a large video with a big transcript that can't be passed into the context window of an llm. llms now adays have started to come with much larger context window size, but still what if we have a thousand page document?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf9a3afb-e468-4b26-a1ab-105fa734137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define prompt for the map phase\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Write a concise summary of the following:\\n\\n{context}\")]\n",
    ")  # Define a prompt to summarize each chunk of the content\n",
    "\n",
    "# Create map chain that summarizes each chunk individually\n",
    "map_chain = map_prompt | llm | StrOutputParser()  # Create a chain that maps the prompt to the LLM and parses the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c801d86-f789-4528-8f65-da20040ccde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reduce template and prompt for consolidation\n",
    "reduce_template = \"\"\"\n",
    "The following is a set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary\n",
    "of the main themes.\n",
    "\"\"\"  # Template to instruct the LLM to consolidate multiple summaries\n",
    "reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()  # Create a chain to reduce the mapped summaries into a final summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1dde2d9-985a-4d87-9c47-879840f27e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "# Split the subtitles into chunks for map reduce\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")  # Split the content into chunks of 1000 characters without overlap to make it manageable for the LLM\n",
    "# we can also use the overlap, this helps to create a continuity between chunks. that means each chunk will have a couple of words, say - 50 from the prev chunk too.\n",
    "\n",
    "split_subtitles = text_splitter.split_documents(subtitles)  # Split the subtitles document into smaller chunks\n",
    "print(f\"Generated {len(split_subtitles)} documents.\")  # Print the number of generated chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05160142-15ff-4504-aaad-ad381772ca56",
   "metadata": {},
   "source": [
    "Generated 1 document because the transcript size is too small to actually be divided. ie less than chunk size -1000.\n",
    "\n",
    "Try to summarize a big video and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2aab2a8b-1d68-453b-ab80-68621e68c6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map Reduce Method Summary:\n",
      "Here is a consolidated summary of the main themes:\n",
      "\n",
      "**Python's Popularity and Versatility**\n",
      "\n",
      "* Python is the world's fastest-growing and most popular programming language, used by people from various disciplines, including software engineers, mathematicians, data analysts, scientists, accountants, and kids.\n",
      "* It's a beginner-friendly language that can be used for a variety of tasks, such as data analysis and visualization, artificial intelligence and machine learning, automation, web and mobile development, and software testing.\n",
      "\n",
      "**Advantages of Python**\n",
      "\n",
      "* Python allows users to solve complex problems in less time with fewer lines of code, making it a more efficient language.\n",
      "* It has a simple, clean, and powerful syntax, making it easy to learn and use.\n",
      "* Python is a high-level language, so users don't have to worry about complex tasks like memory management.\n",
      "* It's cross-platform, allowing users to build and run applications on Windows, Mac, and Linux.\n",
      "* Python has a huge community and a large ecosystem of libraries, frameworks, and tools, making it easy to find help and resources.\n",
      "\n",
      "**Why Python is Awesome**\n",
      "\n",
      "* Python's simplicity and elegance have made it grow more popular than other programming languages.\n",
      "* It's a multi-purpose language that can be used for a wide range of tasks, making it a valuable skill to have.\n",
      "* Learning Python opens up many job opportunities, with the average Python developer earning $116,000 per year.\n",
      "\n",
      "Overall, the summary highlights Python's versatility, ease of use, and popularity, making it a valuable skill to learn for anyone interested in programming.\n"
     ]
    }
   ],
   "source": [
    "# Invoke reduce chain on the split subtitles\n",
    "print(\"Map Reduce Method Summary:\")\n",
    "print(reduce_chain.invoke(split_subtitles))  # Print the consolidated summary from the Map Reduce method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af310ec-ce49-4280-994e-f79f4d5e3f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e067db83-8897-41d3-a430-4db188a4dacd",
   "metadata": {},
   "source": [
    "Some of the sources (that I remeber) are - vidyaanalytics, langchain documents, a couple of yt videos and gpt (ofcourse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41fe3a-a7f5-448d-aad8-bc74c4188423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
